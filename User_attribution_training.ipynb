{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "N4w0AKlTZCBK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from datasets import load_metric\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from torch.utils.data import (\n",
    "    DataLoader, TensorDataset\n",
    ") \n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2_Fo7eQfXlo",
    "outputId": "e5ac5382-4e71-4e67-b7b0-d950992675f3"
   },
   "outputs": [],
   "source": [
    "#loading train dataset\n",
    "train_data = pd.read_csv('split/x_train.csv')\n",
    "val_data = pd.read_csv('split/x_val.csv')\n",
    "test_data = pd.read_csv('split/x_test.csv')\n",
    "\n",
    "train_data = train_data.dropna(subset = ['sar_text'])\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "val_data = val_data.dropna(subset = ['sar_text'])\n",
    "val_data = val_data.reset_index(drop=True)\n",
    "\n",
    "test_data = test_data.dropna(subset = ['sar_text'])\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22622\n"
     ]
    }
   ],
   "source": [
    "users = []\n",
    "train_users = []\n",
    "\n",
    "for i in range(len(train_data['sar_user'])):\n",
    "    user = train_data['sar_user'][i].split('|')\n",
    "    users.append(int(user[-1]))\n",
    "    train_users.append(int(user[-1]))\n",
    "    \n",
    "for i in range(len(val_data['sar_user'])):\n",
    "    user = val_data['sar_user'][i].split('|')\n",
    "    users.append(int(user[-1]))\n",
    "    \n",
    "for i in range(len(test_data['sar_user'])):\n",
    "    user = test_data['sar_user'][i].split('|')\n",
    "    users.append(int(user[-1]))\n",
    "    \n",
    "#number of disctinct users\n",
    "users = list(dict.fromkeys(users))\n",
    "train_users = list(dict.fromkeys(train_users))\n",
    "num_users = len(users)\n",
    "print(num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function \n",
    "def str_to_arr(string_array):\n",
    "    string_array = string_array.replace(\"[\", \"\")\n",
    "    string_array = string_array.replace(\"]\", \"\")\n",
    "    string_array = string_array.replace(\"\\n\", \"\")\n",
    "    string_array = string_array.replace(\"  \", \" \")\n",
    "    string_array = string_array.split(' ')\n",
    "\n",
    "    for i in range(768):\n",
    "        if string_array[i] == '':\n",
    "            string_array.pop(i)\n",
    "            \n",
    "    if len(string_array) != 768:\n",
    "        print(\"Duzina string arraya \", len(string_array))\n",
    "    \n",
    "    return [float(string_number) for string_number in string_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading embeddings (for all the users)\n",
    "file = open('/../../../data/sarcasm_data/user_embeddings_3_final.csv')\n",
    "\n",
    "embedding = []\n",
    "tweets_to_users = {}\n",
    "tweet_to_id = {}\n",
    "\n",
    "num_tweets = 0\n",
    "for line in file:\n",
    "    tweet_id, tweet_embedding, user_id = line.split(',')\n",
    "    \n",
    "    if int(user_id) in users and tweet_id not in tweets_to_users:\n",
    "    #    embedding.extend(str_to_arr(tweet_embedding))\n",
    "        tweets_to_users[tweet_id] = user_id\n",
    "        tweet_to_id[tweet_id] = len(tweet_to_id)\n",
    "        num_tweets += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246293\n",
      "2246293\n",
      "2246293\n"
     ]
    }
   ],
   "source": [
    "print(len(tweets_to_users))\n",
    "print(len(tweet_to_id))\n",
    "print(num_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting users from the history folder\n",
    "history_users = list(tweets_to_users.values())\n",
    "history_users = list(dict.fromkeys(history_users))\n",
    "\n",
    "i = 0\n",
    "for user in history_users:\n",
    "    history_users[i] = int(user.replace('\\n',''))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22315"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(history_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the tweets to users\n",
    "with open('tweets_to_users.pkl', 'wb') as f:\n",
    "    pickle.dump(tweets_to_users, f)\n",
    "    \n",
    "#all the tweets to ids\n",
    "with open('tweets_to_ids.pkl', 'wb') as f:\n",
    "    pickle.dump(tweet_to_id, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating embedding layer (if it doesn't exist)\n",
    "embedding = np.reshape(embedding, (-1, 768))\n",
    "np.save('embdedding_matrix.npy',embedding)\n",
    "final_embedding = torch.from_numpy(embedding)\n",
    "embedding_layer = nn.Embedding.from_pretrained(final_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the embedding layer\n",
    "with open('embdedding_matrix.npy', 'rb') as f:\n",
    "    embeddings = np.load(f)\n",
    "final_embedding = torch.from_numpy(embeddings)\n",
    "embedding_layer = nn.Embedding.from_pretrained(final_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(2246293, 768)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15329\n",
      "22315\n"
     ]
    }
   ],
   "source": [
    "#creating labels for training authors\n",
    "author_to_label = {}\n",
    "\n",
    "i = 0\n",
    "for user in train_users:    \n",
    "    if user not in author_to_label and user in history_users:\n",
    "        author_to_label[user] = i\n",
    "        i += 1\n",
    "        \n",
    "print(len(author_to_label))\n",
    "        \n",
    "#creating labels for the rest of the authors\n",
    "for user in users:    \n",
    "    if user not in author_to_label and user in history_users:\n",
    "        author_to_label[user] = i\n",
    "        i += 1\n",
    "        \n",
    "print(len(author_to_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('author_to_label.pkl', 'wb') as f:\n",
    "    pickle.dump(author_to_label, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just the users from training\n",
    "all_labels = []\n",
    "all_tweets = []\n",
    "\n",
    "for tweet_id in tweets_to_users:\n",
    "    \n",
    "    user = int(tweets_to_users[tweet_id].replace('\\n',''))\n",
    "    \n",
    "    if user in train_users and user in history_users:\n",
    "\n",
    "        all_labels.append(author_to_label[user])\n",
    "        all_tweets.append(tweet_to_id[tweet_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1548879"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1548879"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "batch_size = 64\n",
    "SEED = 1234\n",
    "\n",
    "train_tweets, val_tweets, train_labels, val_labels = train_test_split(all_tweets, all_labels, test_size=0.2)\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(np.asarray(train_tweets)), torch.from_numpy(np.asarray(train_labels)))\n",
    "train_loader = DataLoader(train_dataset, shuffle=False, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "val_dataset = TensorDataset(torch.from_numpy(np.asarray(val_tweets)), torch.from_numpy(np.asarray(val_labels)))\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")\n",
    "    \n",
    "torch.cuda.set_device(1)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "KEHEIm9nYQyT"
   },
   "outputs": [],
   "source": [
    "#2LL Network\n",
    "class MLPAttribution(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = self.relu(self.linear1(input))\n",
    "        return self.linear2(F.dropout(output, p=0.2, training=self.training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "bbIA1AnLcXtY"
   },
   "outputs": [],
   "source": [
    "#helper function\n",
    "def evaluate_mlp(model, dataloader):\n",
    "    accuracy_metric = load_metric(\"accuracy\")\n",
    "    f1_macro = load_metric(\"f1\")\n",
    "    f1_weighted = load_metric(\"f1\")\n",
    "   \n",
    "    model.eval()    \n",
    "    \n",
    "    model = model.float()\n",
    "    for batch in dataloader:\n",
    "        with torch.no_grad():\n",
    "            input = batch[0]\n",
    "            labels = batch[1].to(device)\n",
    "            embedding = embedding_layer(input).to(device)\n",
    "            logits = model(embedding.float())\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        accuracy_metric.add_batch(predictions=predictions, references=labels)\n",
    "        f1_macro.add_batch(predictions=predictions, references=labels)\n",
    "        f1_weighted.add_batch(predictions=predictions, references=labels)\n",
    "\n",
    "    return {'accuracy': accuracy_metric.compute()['accuracy'], 'f1_score_macro': f1_macro.compute(average=\"macro\")['f1'], \n",
    "        'f1_score_weighted': f1_weighted.compute(average=\"weighted\")['f1']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "U43hoh_AaQHV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15329\n"
     ]
    }
   ],
   "source": [
    "#number of users in train\n",
    "output_dim = len(list(dict.fromkeys(all_labels)))\n",
    "print(output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "2G9Ae6o_aMDB"
   },
   "outputs": [],
   "source": [
    "model = MLPAttribution(768, 384, output_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "zXKk6nLraOy_"
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "best_accuracy = 0\n",
    "best_f1 = 0\n",
    "samples_per_class = torch.bincount(torch.tensor(all_labels)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CB_loss(labels, logits, samples_per_cls, no_of_classes, loss_type, beta, gamma):\n",
    "    \"\"\"Compute the Class Balanced Loss between `logits` and the ground truth `labels`.\n",
    "    Class Balanced Loss: ((1-beta)/(1-beta^n))*Loss(labels, logits)\n",
    "    where Loss is one of the standard losses used for Neural Networks.\n",
    "    Args:\n",
    "      labels: A int tensor of size [batch].\n",
    "      logits: A float tensor of size [batch, no_of_classes].\n",
    "      samples_per_cls: A python list of size [no_of_classes].\n",
    "      no_of_classes: total number of classes. int\n",
    "      loss_type: string. One of \"sigmoid\", \"focal\", \"softmax\".\n",
    "      beta: float. Hyperparameter for Class balanced loss.\n",
    "      gamma: float. Hyperparameter for Focal loss.\n",
    "    Returns:\n",
    "      cb_loss: A float tensor representing class balanced loss\n",
    "    \"\"\"\n",
    "    effective_num = 1.0 - np.power(beta, samples_per_cls)\n",
    "    weights = (1.0 - beta) / np.array(effective_num)\n",
    "    weights = weights / np.sum(weights) * no_of_classes\n",
    "\n",
    "    labels_one_hot = F.one_hot(labels, no_of_classes).float()\n",
    "\n",
    "    weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "    weights = weights.unsqueeze(0)\n",
    "    weights = weights.repeat(labels_one_hot.shape[0], 1) * labels_one_hot\n",
    "    weights = weights.sum(1)\n",
    "    weights = weights.unsqueeze(1)\n",
    "    weights = weights.repeat(1, no_of_classes)\n",
    "\n",
    "    if loss_type == \"focal\":\n",
    "        cb_loss = focal_loss(labels_one_hot, logits, weights, gamma)\n",
    "    elif loss_type == \"sigmoid\":\n",
    "        cb_loss = F.binary_cross_entropy_with_logits(input=logits, target=labels_one_hot, weight=weights)\n",
    "    elif loss_type == \"softmax\":\n",
    "        pred = logits.softmax(dim=1)\n",
    "        cb_loss = F.binary_cross_entropy(input=pred, target=labels_one_hot, weight=weights)\n",
    "\n",
    "    return cb_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(output, targets, samples_per_cls, no_of_classes=2, loss_type = \"softmax\"):\n",
    "    beta = 0.9999\n",
    "    gamma = 2.0\n",
    "\n",
    "    return CB_loss(targets, output, samples_per_cls, no_of_classes, loss_type, beta, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "flhII0r2b23O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 **** Loss 0.0006693075411021709 **** Metrics validation: {'accuracy': 0.0007360537190082645, 'f1_score_macro': 3.448788729577643e-05, 'f1_score_weighted': 2.8575128947129812e-05}\n",
      "Epoch 1 **** Loss 0.0006280039087869227 **** Metrics validation: {'accuracy': 0.0027634297520661155, 'f1_score_macro': 0.0004702338373286316, 'f1_score_weighted': 0.0004551465427733109}\n",
      "Epoch 2 **** Loss 0.0006047406350262463 **** Metrics validation: {'accuracy': 0.006230630165289256, 'f1_score_macro': 0.0016503023089930958, 'f1_score_weighted': 0.0016663771935469317}\n",
      "Epoch 3 **** Loss 0.0005875469068996608 **** Metrics validation: {'accuracy': 0.009581611570247934, 'f1_score_macro': 0.0029144205169197718, 'f1_score_weighted': 0.002999214433726065}\n",
      "Epoch 4 **** Loss 0.0005787684349343181 **** Metrics validation: {'accuracy': 0.01306172520661157, 'f1_score_macro': 0.0045341420979390845, 'f1_score_weighted': 0.004646668852316484}\n",
      "Epoch 5 **** Loss 0.0005670087994076312 **** Metrics validation: {'accuracy': 0.016419163223140496, 'f1_score_macro': 0.00629259856139599, 'f1_score_weighted': 0.006462964916321569}\n",
      "Epoch 6 **** Loss 0.000557123392354697 **** Metrics validation: {'accuracy': 0.01920519111570248, 'f1_score_macro': 0.007810620493716161, 'f1_score_weighted': 0.008046196879988214}\n",
      "Epoch 7 **** Loss 0.0005526618915610015 **** Metrics validation: {'accuracy': 0.021807205578512397, 'f1_score_macro': 0.009351857266890634, 'f1_score_weighted': 0.009646588984209569}\n",
      "Epoch 8 **** Loss 0.0005467206356115639 **** Metrics validation: {'accuracy': 0.02424457644628099, 'f1_score_macro': 0.011069983094673068, 'f1_score_weighted': 0.01140314613364634}\n",
      "Epoch 9 **** Loss 0.0005397458444349468 **** Metrics validation: {'accuracy': 0.026410769628099174, 'f1_score_macro': 0.012576945840331043, 'f1_score_weighted': 0.012941623110006437}\n",
      "Epoch 10 **** Loss 0.0005390755250118673 **** Metrics validation: {'accuracy': 0.02839294938016529, 'f1_score_macro': 0.01410491724669279, 'f1_score_weighted': 0.014510727643540111}\n",
      "Epoch 11 **** Loss 0.000527840165887028 **** Metrics validation: {'accuracy': 0.03017497417355372, 'f1_score_macro': 0.015584954021711664, 'f1_score_weighted': 0.016034136812167255}\n",
      "Epoch 12 **** Loss 0.0005283022182993591 **** Metrics validation: {'accuracy': 0.03190857438016529, 'f1_score_macro': 0.01698179040041896, 'f1_score_weighted': 0.01746203995109459}\n",
      "Epoch 13 **** Loss 0.0005189720541238785 **** Metrics validation: {'accuracy': 0.033190211776859505, 'f1_score_macro': 0.01811174181279553, 'f1_score_weighted': 0.018626505793505287}\n",
      "Epoch 14 **** Loss 0.0005163001478649676 **** Metrics validation: {'accuracy': 0.034539643595041324, 'f1_score_macro': 0.019291992741521203, 'f1_score_weighted': 0.0198599263111106}\n",
      "Epoch 15 **** Loss 0.0005149791250005364 **** Metrics validation: {'accuracy': 0.035776084710743804, 'f1_score_macro': 0.020456062682136424, 'f1_score_weighted': 0.021089141677651295}\n",
      "Epoch 16 **** Loss 0.0005063524004071951 **** Metrics validation: {'accuracy': 0.03685756714876033, 'f1_score_macro': 0.021551347076536078, 'f1_score_weighted': 0.0221855650282969}\n",
      "Epoch 17 **** Loss 0.0005125062307342887 **** Metrics validation: {'accuracy': 0.03787448347107438, 'f1_score_macro': 0.022447036220341037, 'f1_score_weighted': 0.02313351082040251}\n",
      "Epoch 18 **** Loss 0.0004992274334654212 **** Metrics validation: {'accuracy': 0.03879132231404959, 'f1_score_macro': 0.02344724551036807, 'f1_score_weighted': 0.024106245988938606}\n",
      "Epoch 19 **** Loss 0.0005069504259154201 **** Metrics validation: {'accuracy': 0.039650051652892565, 'f1_score_macro': 0.024310906586476316, 'f1_score_weighted': 0.025016253778724247}\n",
      "Epoch 20 **** Loss 0.0005008892039768398 **** Metrics validation: {'accuracy': 0.04037964876033058, 'f1_score_macro': 0.025069891860349316, 'f1_score_weighted': 0.025760060657303487}\n",
      "Epoch 21 **** Loss 0.0004952788585796952 **** Metrics validation: {'accuracy': 0.04101885330578513, 'f1_score_macro': 0.025847687786295568, 'f1_score_weighted': 0.02655428714437052}\n",
      "Epoch 22 **** Loss 0.0004910790012218058 **** Metrics validation: {'accuracy': 0.04168388429752066, 'f1_score_macro': 0.026591552365741136, 'f1_score_weighted': 0.027292678758010693}\n",
      "Epoch 23 **** Loss 0.0004987767315469682 **** Metrics validation: {'accuracy': 0.042264979338842976, 'f1_score_macro': 0.027269541080232034, 'f1_score_weighted': 0.02802321135091639}\n",
      "Epoch 24 **** Loss 0.0004907858674414456 **** Metrics validation: {'accuracy': 0.04274922520661157, 'f1_score_macro': 0.02776219093349487, 'f1_score_weighted': 0.028514283242406617}\n",
      "Epoch 25 **** Loss 0.0004834174760617316 **** Metrics validation: {'accuracy': 0.04315922004132231, 'f1_score_macro': 0.02838311983763096, 'f1_score_weighted': 0.02912875824599715}\n",
      "Epoch 26 **** Loss 0.00048384928959421813 **** Metrics validation: {'accuracy': 0.04378873966942149, 'f1_score_macro': 0.029055767442874993, 'f1_score_weighted': 0.02981364877420336}\n",
      "Epoch 27 **** Loss 0.00048133538803085685 **** Metrics validation: {'accuracy': 0.04415676652892562, 'f1_score_macro': 0.029589428183626174, 'f1_score_weighted': 0.03035020355853852}\n",
      "Epoch 28 **** Loss 0.0004735339025501162 **** Metrics validation: {'accuracy': 0.04457321797520661, 'f1_score_macro': 0.030065993842948658, 'f1_score_weighted': 0.030846512279726797}\n",
      "Epoch 29 **** Loss 0.0004737710114568472 **** Metrics validation: {'accuracy': 0.044854080578512395, 'f1_score_macro': 0.03052625922037377, 'f1_score_weighted': 0.0313228172457127}\n",
      "Epoch 30 **** Loss 0.00047412453568540514 **** Metrics validation: {'accuracy': 0.045128486570247935, 'f1_score_macro': 0.030927426223968324, 'f1_score_weighted': 0.031746688628156126}\n",
      "Epoch 31 **** Loss 0.00047554250340908766 **** Metrics validation: {'accuracy': 0.045615960743801656, 'f1_score_macro': 0.03135750848721099, 'f1_score_weighted': 0.03219592198104671}\n",
      "Epoch 32 **** Loss 0.0004592958139255643 **** Metrics validation: {'accuracy': 0.04587745351239669, 'f1_score_macro': 0.031730468832281554, 'f1_score_weighted': 0.03256005519850151}\n",
      "Epoch 33 **** Loss 0.00046056139399297535 **** Metrics validation: {'accuracy': 0.04613571797520661, 'f1_score_macro': 0.03216832847599847, 'f1_score_weighted': 0.03301708841150394}\n",
      "Epoch 34 **** Loss 0.0004712680238299072 **** Metrics validation: {'accuracy': 0.04635201446280992, 'f1_score_macro': 0.03246856930098971, 'f1_score_weighted': 0.0333185737354217}\n",
      "Epoch 35 **** Loss 0.0004663231666199863 **** Metrics validation: {'accuracy': 0.04654248450413223, 'f1_score_macro': 0.03285016620996078, 'f1_score_weighted': 0.03367789320898382}\n",
      "Epoch 36 **** Loss 0.0004659219121094793 **** Metrics validation: {'accuracy': 0.04663610537190083, 'f1_score_macro': 0.03306434152371588, 'f1_score_weighted': 0.033883290201552604}\n",
      "Epoch 37 **** Loss 0.0004575151251628995 **** Metrics validation: {'accuracy': 0.04685240185950413, 'f1_score_macro': 0.0333663399660717, 'f1_score_weighted': 0.0341982484277875}\n",
      "Epoch 38 **** Loss 0.0004572098550852388 **** Metrics validation: {'accuracy': 0.04702995867768595, 'f1_score_macro': 0.033612398903974036, 'f1_score_weighted': 0.034446770725930075}\n",
      "Epoch 39 **** Loss 0.0004621913540177047 **** Metrics validation: {'accuracy': 0.04715263429752066, 'f1_score_macro': 0.033867420438463865, 'f1_score_weighted': 0.034720352761952296}\n",
      "Epoch 40 **** Loss 0.0004652218194678426 **** Metrics validation: {'accuracy': 0.047197830578512394, 'f1_score_macro': 0.03403524662147791, 'f1_score_weighted': 0.034882309881117755}\n",
      "Epoch 41 **** Loss 0.0004587222938425839 **** Metrics validation: {'accuracy': 0.047349560950413226, 'f1_score_macro': 0.03430827887141577, 'f1_score_weighted': 0.03515949953346607}\n",
      "Epoch 42 **** Loss 0.00045741721987724304 **** Metrics validation: {'accuracy': 0.04740121384297521, 'f1_score_macro': 0.034494452016374993, 'f1_score_weighted': 0.03536860929795872}\n",
      "Epoch 43 **** Loss 0.000452924519777298 **** Metrics validation: {'accuracy': 0.0475884555785124, 'f1_score_macro': 0.034789775629553, 'f1_score_weighted': 0.035639878967892974}\n",
      "Epoch 44 **** Loss 0.0004491859581321478 **** Metrics validation: {'accuracy': 0.04765302169421488, 'f1_score_macro': 0.034942086836563725, 'f1_score_weighted': 0.03580360357457952}\n",
      "Epoch 45 **** Loss 0.00045520818093791604 **** Metrics validation: {'accuracy': 0.047604597107438015, 'f1_score_macro': 0.034975415860014805, 'f1_score_weighted': 0.035845856912921956}\n",
      "Epoch 46 **** Loss 0.0004529991711024195 **** Metrics validation: {'accuracy': 0.047682076446280995, 'f1_score_macro': 0.03515355805719864, 'f1_score_weighted': 0.03602523099713013}\n",
      "Epoch 47 **** Loss 0.0004335461708251387 **** Metrics validation: {'accuracy': 0.04778538223140496, 'f1_score_macro': 0.03527046056902499, 'f1_score_weighted': 0.03614575645279799}\n",
      "Epoch 48 **** Loss 0.0004434170841705054 **** Metrics validation: {'accuracy': 0.04789191632231405, 'f1_score_macro': 0.03544285981920034, 'f1_score_weighted': 0.03632360200570378}\n",
      "Epoch 49 **** Loss 0.00043985567754134536 **** Metrics validation: {'accuracy': 0.04790160123966942, 'f1_score_macro': 0.035610427452062395, 'f1_score_weighted': 0.03651044071451869}\n",
      "Epoch 50 **** Loss 0.0004519587382674217 **** Metrics validation: {'accuracy': 0.04812112603305785, 'f1_score_macro': 0.03585263641127661, 'f1_score_weighted': 0.036726932643953755}\n",
      "Epoch 51 **** Loss 0.0004599631647579372 **** Metrics validation: {'accuracy': 0.04816632231404959, 'f1_score_macro': 0.03588808589540775, 'f1_score_weighted': 0.036767940641067046}\n",
      "Epoch 52 **** Loss 0.0004412969574332237 **** Metrics validation: {'accuracy': 0.047933884297520664, 'f1_score_macro': 0.03574566834215594, 'f1_score_weighted': 0.03663290183364908}\n",
      "Epoch 53 **** Loss 0.0004538521752692759 **** Metrics validation: {'accuracy': 0.0479790805785124, 'f1_score_macro': 0.035929016329329246, 'f1_score_weighted': 0.03679938662972647}\n",
      "Epoch 54 **** Loss 0.00043948920210823417 **** Metrics validation: {'accuracy': 0.047995222107438014, 'f1_score_macro': 0.03593953728050134, 'f1_score_weighted': 0.03680955569569635}\n",
      "Epoch 55 **** Loss 0.0004551802412606776 **** Metrics validation: {'accuracy': 0.04807915805785124, 'f1_score_macro': 0.03611300531265632, 'f1_score_weighted': 0.03696220762697406}\n",
      "Epoch 56 **** Loss 0.00042613837285898626 **** Metrics validation: {'accuracy': 0.0481146694214876, 'f1_score_macro': 0.03623621579092831, 'f1_score_weighted': 0.037115207318352036}\n",
      "Epoch 57 **** Loss 0.0004519068752415478 **** Metrics validation: {'accuracy': 0.0481953770661157, 'f1_score_macro': 0.036400363182731314, 'f1_score_weighted': 0.037264510584986844}\n",
      "Epoch 58 **** Loss 0.000437144044553861 **** Metrics validation: {'accuracy': 0.048066244834710746, 'f1_score_macro': 0.036400903023175786, 'f1_score_weighted': 0.03730366964373566}\n",
      "Epoch 59 **** Loss 0.0004390699905343354 **** Metrics validation: {'accuracy': 0.048321280991735535, 'f1_score_macro': 0.03664030421903409, 'f1_score_weighted': 0.03751771648789786}\n",
      "Epoch 60 **** Loss 0.0004350414383225143 **** Metrics validation: {'accuracy': 0.048211518595041324, 'f1_score_macro': 0.03661932803060435, 'f1_score_weighted': 0.03751332864306425}\n",
      "Epoch 61 **** Loss 0.0004360076563898474 **** Metrics validation: {'accuracy': 0.04833419421487603, 'f1_score_macro': 0.03677165323127901, 'f1_score_weighted': 0.037705634693555236}\n",
      "Epoch 62 **** Loss 0.0004391779366414994 **** Metrics validation: {'accuracy': 0.04822766012396694, 'f1_score_macro': 0.036754535915189714, 'f1_score_weighted': 0.037676156393239305}\n",
      "Epoch 63 **** Loss 0.00045356363989412785 **** Metrics validation: {'accuracy': 0.0481146694214876, 'f1_score_macro': 0.036747273521383995, 'f1_score_weighted': 0.03765233282341979}\n",
      "Epoch 64 **** Loss 0.0004414703871589154 **** Metrics validation: {'accuracy': 0.048179235537190085, 'f1_score_macro': 0.03677045845417369, 'f1_score_weighted': 0.037719086825948246}\n",
      "Epoch 65 **** Loss 0.0004328506765887141 **** Metrics validation: {'accuracy': 0.04822120351239669, 'f1_score_macro': 0.03700850443577683, 'f1_score_weighted': 0.037912738772945445}\n",
      "Epoch 66 **** Loss 0.00043274369090795517 **** Metrics validation: {'accuracy': 0.048146952479338846, 'f1_score_macro': 0.03693090943154231, 'f1_score_weighted': 0.03786550180863055}\n",
      "Epoch 67 **** Loss 0.00043971044942736626 **** Metrics validation: {'accuracy': 0.048237345041322315, 'f1_score_macro': 0.03701308648765418, 'f1_score_weighted': 0.03792212579564473}\n",
      "Epoch 68 **** Loss 0.00043250314774923027 **** Metrics validation: {'accuracy': 0.048285769628099176, 'f1_score_macro': 0.03708602072496875, 'f1_score_weighted': 0.03803994702186098}\n",
      "Epoch 69 **** Loss 0.00043570014531724155 **** Metrics validation: {'accuracy': 0.04827931301652893, 'f1_score_macro': 0.03718008600211562, 'f1_score_weighted': 0.03808321261902671}\n",
      "Epoch 70 **** Loss 0.0004458707699086517 **** Metrics validation: {'accuracy': 0.04826962809917355, 'f1_score_macro': 0.0371884946686087, 'f1_score_weighted': 0.038076853225834456}\n",
      "Epoch 71 **** Loss 0.0004318470600992441 **** Metrics validation: {'accuracy': 0.04823088842975207, 'f1_score_macro': 0.03718149913764795, 'f1_score_weighted': 0.03811949201286267}\n",
      "Epoch 72 **** Loss 0.00042324152309447527 **** Metrics validation: {'accuracy': 0.04817600723140496, 'f1_score_macro': 0.03719771767345742, 'f1_score_weighted': 0.03806280695480288}\n",
      "Epoch 73 **** Loss 0.0004319563740864396 **** Metrics validation: {'accuracy': 0.04830191115702479, 'f1_score_macro': 0.037407976081341214, 'f1_score_weighted': 0.03826527966437295}\n",
      "Epoch 74 **** Loss 0.0004215009103063494 **** Metrics validation: {'accuracy': 0.04832450929752066, 'f1_score_macro': 0.037370677707404744, 'f1_score_weighted': 0.03824553143228962}\n",
      "Epoch 75 **** Loss 0.0004344044718891382 **** Metrics validation: {'accuracy': 0.0483567923553719, 'f1_score_macro': 0.03756991743894068, 'f1_score_weighted': 0.038467458891240175}\n",
      "Epoch 76 **** Loss 0.00043415281106717885 **** Metrics validation: {'accuracy': 0.04841490185950413, 'f1_score_macro': 0.03763255159127189, 'f1_score_weighted': 0.03850520958280436}\n",
      "Epoch 77 **** Loss 0.0004449519037734717 **** Metrics validation: {'accuracy': 0.04836002066115702, 'f1_score_macro': 0.037551898806276234, 'f1_score_weighted': 0.03839688446516713}\n",
      "Epoch 78 **** Loss 0.0004277036932762712 **** Metrics validation: {'accuracy': 0.04831482438016529, 'f1_score_macro': 0.0375774040990465, 'f1_score_weighted': 0.03846229452270667}\n",
      "Epoch 79 **** Loss 0.00043014014954678714 **** Metrics validation: {'accuracy': 0.048343879132231406, 'f1_score_macro': 0.03762578916704725, 'f1_score_weighted': 0.03849680112899601}\n",
      "Epoch 80 **** Loss 0.00043595340684987605 **** Metrics validation: {'accuracy': 0.0483697055785124, 'f1_score_macro': 0.03771260994580438, 'f1_score_weighted': 0.03860133589937134}\n",
      "Epoch 81 **** Loss 0.00042232172563672066 **** Metrics validation: {'accuracy': 0.04846332644628099, 'f1_score_macro': 0.03779065480236625, 'f1_score_weighted': 0.0386396777154276}\n",
      "Epoch 82 **** Loss 0.000450090883532539 **** Metrics validation: {'accuracy': 0.04841490185950413, 'f1_score_macro': 0.03773625043984023, 'f1_score_weighted': 0.03859121657922796}\n",
      "Epoch 83 **** Loss 0.00041181780397892 **** Metrics validation: {'accuracy': 0.04847623966942149, 'f1_score_macro': 0.03792159317845754, 'f1_score_weighted': 0.03876385801540768}\n",
      "Epoch 84 **** Loss 0.0004233053477946669 **** Metrics validation: {'accuracy': 0.048401988636363635, 'f1_score_macro': 0.03784373604422708, 'f1_score_weighted': 0.03868860787822425}\n",
      "Epoch 85 **** Loss 0.0004273993254173547 **** Metrics validation: {'accuracy': 0.04844072830578512, 'f1_score_macro': 0.03799244796937283, 'f1_score_weighted': 0.038840608846435164}\n",
      "Epoch 86 **** Loss 0.0004270906501915306 **** Metrics validation: {'accuracy': 0.04840521694214876, 'f1_score_macro': 0.0379146585032511, 'f1_score_weighted': 0.03875911948165427}\n",
      "Epoch 87 **** Loss 0.00043555934098549187 **** Metrics validation: {'accuracy': 0.0484504132231405, 'f1_score_macro': 0.037960416268816875, 'f1_score_weighted': 0.03881619808162852}\n",
      "Epoch 88 **** Loss 0.0004161833203397691 **** Metrics validation: {'accuracy': 0.04844395661157025, 'f1_score_macro': 0.037987753106670505, 'f1_score_weighted': 0.038862151433798876}\n",
      "Epoch 89 **** Loss 0.00042287647374905646 **** Metrics validation: {'accuracy': 0.048372933884297524, 'f1_score_macro': 0.038052983781318314, 'f1_score_weighted': 0.03891265208425677}\n",
      "Epoch 90 **** Loss 0.00042630010284483433 **** Metrics validation: {'accuracy': 0.048505294421487606, 'f1_score_macro': 0.03812389117221347, 'f1_score_weighted': 0.03899409683647831}\n",
      "Epoch 91 **** Loss 0.00042630822281353176 **** Metrics validation: {'accuracy': 0.048431043388429754, 'f1_score_macro': 0.03807524307669882, 'f1_score_weighted': 0.03892498100690405}\n",
      "Epoch 92 **** Loss 0.0004349820374045521 **** Metrics validation: {'accuracy': 0.0484375, 'f1_score_macro': 0.038154636124766, 'f1_score_weighted': 0.03902605578836195}\n",
      "Epoch 93 **** Loss 0.0004241693823132664 **** Metrics validation: {'accuracy': 0.04841490185950413, 'f1_score_macro': 0.03811244135222464, 'f1_score_weighted': 0.03896824149330982}\n",
      "Epoch 94 **** Loss 0.0004126938001718372 **** Metrics validation: {'accuracy': 0.04844718491735537, 'f1_score_macro': 0.038300404988776224, 'f1_score_weighted': 0.039124466277833524}\n",
      "Epoch 95 **** Loss 0.00042553467210382223 **** Metrics validation: {'accuracy': 0.04825348657024793, 'f1_score_macro': 0.03810559378567337, 'f1_score_weighted': 0.03897483624350522}\n",
      "Epoch 96 **** Loss 0.0004263791488483548 **** Metrics validation: {'accuracy': 0.04846978305785124, 'f1_score_macro': 0.03827119726886194, 'f1_score_weighted': 0.0391183793145524}\n",
      "Epoch 97 **** Loss 0.0004404063511174172 **** Metrics validation: {'accuracy': 0.04846332644628099, 'f1_score_macro': 0.0383704597837723, 'f1_score_weighted': 0.039211370799972535}\n",
      "Epoch 98 **** Loss 0.0004317358252592385 **** Metrics validation: {'accuracy': 0.048288997933884296, 'f1_score_macro': 0.03818928304612698, 'f1_score_weighted': 0.03905421640983066}\n",
      "Epoch 99 **** Loss 0.00042415587813593447 **** Metrics validation: {'accuracy': 0.04832773760330578, 'f1_score_macro': 0.038288408500521884, 'f1_score_weighted': 0.0391183514805065}\n"
     ]
    }
   ],
   "source": [
    "model = model.float()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        input = batch[0]\n",
    "        labels = batch[1].to(device)\n",
    "        embedding = embedding_layer(input).to(device)\n",
    "        output = model(embedding.float())\n",
    "        pred = output.softmax(dim=1)\n",
    "        loss = loss_fn(output, labels, samples_per_class, output_dim)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    val_metric = evaluate_mlp(model, val_loader)\n",
    "\n",
    "    print(\"Epoch {} **** Loss {} **** Metrics validation: {}\".format(epoch, loss, val_metric))\n",
    "    if val_metric['f1_score_weighted'] > best_f1:\n",
    "        best_f1 = val_metric['f1_score_weighted']\n",
    "        torch.save(model.state_dict(), './state_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2LL Network.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
